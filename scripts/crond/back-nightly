#!/bin/bash

##
##  See COPYING file distributed along with the ncanda-data-integration package
##  for the copyright and license terms
##

IMAGE_PROCESS_FLAG=1
PIPELINE_UPDATE_FLAG=1


if [ "`ps -ef | grep crond/back-nightly | grep -v grep`" != "" ]; then 
   echo "Info: Skipping back-nightly as instance of it is still running"
   exit 0
fi 


# Set the SIBIS environment variable to the data integration repo
export SIBIS=`realpath $(dirname $0)/../../`

# When generating a release do not update pipeline
# exit 0
[ -r $HOME/.bashrc ] && . $HOME/.bashrc

# Import some useful functions
. $(dirname $0)/crontools.sh

#
# Previously front-hourly (all code after harvester runs)
#

LOG_DIR=${SIBIS_ANALYSIS_DIR}/log/back-nightly
# Over the weekend run full version
Day=$(date +%a)
if [ "$Day" == "Sat" -o  "$Day" == "Fri" ]; then 
    update_args=""
    print "Info: update_visit_data checks all forms"
else 
    update_args+=" --missing-only"
fi 

catch_output_email "Import Laptop Data Import (update_visit_data)" ${SIBIS}/scripts/import/laptops/update_visit_data -p -t ${LOG_DIR} --max-days-after-visit 120 ${update_args}

catch_output_email "Update Form Status (update_bulk_forms)" ${SIBIS}/scripts/redcap/update_bulk_forms -p -t ${LOG_DIR}

#
# Previouly front-nighlty
#

######################################
# XNAT / Imaging Related
######################################

if [ ${IMAGE_PROCESS_FLAG} == 1 ]; then
  # Check MR session names etc. in XNAT
  catch_output_email "XNAT: Check Session Names (check_object_names)" ${SIBIS}/scripts/xnat/check_object_names -p -t ${LOG_DIR} --send-mail --zip-root ${SIBIS_ANALYSIS_DIR}/burn2dvd

  # Check for new or updated sessions and
  catch_output_email "XNAT: Check New Sessions (check_new_sessions)" ${SIBIS}/scripts/xnat/check_new_sessions --send-mail-to ncanda-image-qc@sri.com -p -t ${LOG_DIR}
  # --qc-csv ${SIBIS_ANALYSIS_DIR}/beta/image-qc/scan_qc.csv

  # Check whether any MR sessions are missing corresponding phantom scans
  catch_output_email "XNAT: Check Phantom Scan (check_phantom_scans)" ${SIBIS}/scripts/xnat/check_phantom_scans --check-all -p -t ${LOG_DIR}

  # Run fMRI QA on subjects ## Currently disabled because it isn't looked at but takes a long time to run
  ##catch_output_email "XNAT: Subject fMRI QA Messages" ${SIBIS}/scripts/xnat/fmri_qa_subjects
else 
    echo "back-nightly: Warning: Image data is not updated !"   
fi 
 
######################################
# REDCap / NP / Clinical Data Related
######################################

# Import data from UPenn into REDCap
catch_output_email "Import WebCNP to REDCap (cnp2redcap)" ${SIBIS}/scripts/import/webcnp/cnp2redcap -p -t ${LOG_DIR} --last-3-months

# Check whether subject birth dates and gender match checksum digit, plus whether all subjects on study arms appear in main arm also
catch_output_email "REDCap: Subject ID Checks (check_subject_ids)" ${SIBIS}/scripts/redcap/check_subject_ids -p -t ${LOG_DIR}

# Check (and update, if necessary) drinking exception status
catch_output_email "REDCap: Undeclared Drinking Exceptions (check_exceptions)" ${SIBIS}/scripts/redcap/check_exceptions -p -t ${LOG_DIR} --update-fn

#
# Original back-nightly
#

if [ ${PIPELINE_UPDATE_FLAG} == 1 ]; then
    if [ ${IMAGE_PROCESS_FLAG} == 1 ]; then
	# Import data from XNAT into REDCap and feed image analysis pipeline
	catch_output_email "REDCap: Import MR to Pipeline (import_mr_sessions)" ${SIBIS}/scripts/redcap/import_mr_sessions -p --max-days-after-visit 120 --pipeline-root-dir ${SIBIS_ANALYSIS_DIR}/cases --run-pipeline-script ${SIBIS_ANALYSIS_DIR}/scripts/bin/ncanda_all_pipelines -t ${LOG_DIR}
    fi 

    # Export NP/clinical/dempgraphics data into image analysis pipeline directories
    #   This needs to come AFTER "import_mr_sessions", because otherwise we cannot get ages-at-MRI from REDCap for the export.
    catch_output_email "REDCap: Import REDCap to Pipeline (export_measures)" ${SIBIS}/scripts/redcap/export_measures --datadict-dir ${SIBIS_ANALYSIS_DIR}/datadict/redcap --locked_form_report ${SIBIS_ANALYSIS_DIR}/cases

    # Update CSV summary files for the working pipeline
    catch_output_email "Pipeline Summaries (update_csv_summaries)" ${SIBIS}/scripts/reporting/update_csv_summaries ${SIBIS_ANALYSIS_DIR}/cases/ ${SIBIS_ANALYSIS_DIR}/summaries
else 
    echo "back-nightly: Warning: Pipeline is not updated !"   
fi 

# Remove pyxnat cache directory to conserve space
catch_output_email "Drop pyXNAT Cache Directory" rm -rf /tmp/RestAPI@localhost_8080.xnat /tmp/cache
