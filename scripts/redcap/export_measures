#!/usr/bin/env python

##
##  See COPYING file distributed along with the ncanda-data-integration package
##  for the copyright and license terms
##

from __future__ import print_function
from __future__ import division
from builtins import str
from past.utils import old_div
import os
import re
import sys
import argparse
import datetime
import hashlib

import yaml
import pandas

import sibispy
from sibispy import sibislogger as slog
from sibispy import redcap_to_casesdir
from sibispy import utils as sutils
from sibispy import redcap_locking_data

# Setup command line parser
parser = argparse.ArgumentParser( description="For all subjects and visits in the REDCap database, export demographics, clinical measures, NP test scores, and other configured information into the pipeline directory tree.", formatter_class=argparse.ArgumentDefaultsHelpFormatter )
parser.add_argument( "-v", "--verbose", help="Verbose operation", action="store_true")
parser.add_argument( "--locked_form_report", help="Output a report indicating locked forms ", action="store_true")
parser.add_argument( "--site", help="Limit export by site (SRI, UCSD, OHSU, UPMC, DUKE). Multiple sites can be listed, separated by comma (',')", action="store", default=None )
parser.add_argument( "--events", help="Limit export by event labels (e.g., 'baseline_visit_arm_1'). Multiple events can be listed, separated by comma (',')", action="store", default=None )
parser.add_argument( "--subject", help="Limit export by subject site id (e.g., 'X-12345-X-9').", action="store", default=None )
parser.add_argument( "--export", help="Limit export by output file (e.g., 'cddr'; do not include '.txt' suffix). Multiple exports can be listed, separated by comma (',')", action="store", default=None )
parser.add_argument( "-e", "--exclude", help="Exports Meausres for excluded subjects", action="store_true" )
parser.add_argument( "--datadict-dir", help="Provides a directory in which the script creates data dictionaries for all supported export files.", action="store", default=None )
parser.add_argument( "pipelinedir", help="Root directory of the image analysis pipeline.", action="store")
parser.add_argument("-p", "--post-to-github", help="Post all issues to GitHub instead of std out.",action="store_true")
parser.add_argument("-t", "--time-log-dir",
                    help="If set then time logs are written to that directory",
                    action="store",
                    default=None)
args = parser.parse_args()

slog.init_log(args.verbose, args.post_to_github, 'NCANDA ', 'export_measures',
                args.time_log_dir)
slog.startTimer1()

global uploads
uploads = 0

# Open connection with REDCap server
session = sibispy.Session()
if not session.configure(ordered_config_load_flag = True):
    if args.verbose:
        print("Error: session configure file was not found")

    sys.exit()

# Site changes are mapped here to the correct case identifier.
sibis_config = session.get_operations_dir()
special_cases_file = os.path.join(sibis_config, 'special_cases.yml')
if not os.path.isfile(special_cases_file) :
    slog.info("export_measures","Error: The following file does not exist :" + special_cases_file)
    sys.exit(1)

# Get a map of subjects that changed sited
with open(os.path.join(sibis_config, 'special_cases.yml')) as fi:
    special_cases_map=yaml.load(fi)
    site_change_map = special_cases_map.get('site_change')
    export_measures_map = site_change_map.get('export_measures')

    exceeds_criteria_baseline = special_cases_map.get('exceeds_criteria_baseline')

redcap_project = session.connect_server('data_entry', True)
if not redcap_project :
    if args.verbose:
        slog.info("export_measures","Error: Could not connect to Redcap")

    sys.exit()

red2cas = redcap_to_casesdir.redcap_to_casesdir() 
if not red2cas.configure(session,redcap_project.metadata) :
    sys.exit(1)


if not session.connect_server('redcap_mysql_db', True) :
    if args.verbose:
        slog.info("export_measures","Error: Could not connect to redcap mysql db")

    sys.exit(1)

red_lock = redcap_locking_data.redcap_locking_data()
red_lock.configure(session)

forms = list(redcap_project.forms)

# Organize REDCap metadata, e.g., filter all confidential fields out of export lists, and make code-to-label lookup dictionaries
#red.organize_metadata( redcap_project.metadata )
# now done part as part of the configure statement 

form_event_mapping = redcap_project.export_fem( format='df' )

# Get the 'form'/'form_name' used by this version of Redcap
form_key = session.get_redcap_form_key()

# If a directory for creating data dictionaries is given, make those first
if args.datadict_dir:
    red2cas.create_all_datadicts(args.datadict_dir)

# Open a connection with REDCap MySQL server.
if args.locked_form_report:
    engine = session.connect_server('redcap_mysql_db', True)
    if not engine :
        if args.verbose:
            print("Error: Could not connect to REDCap mysql db")

        sys.exit(1)

    if args.verbose:
        print("Configured to output a report of locked forms...")
        print("Connected to REDCap MySQL: {0}".format(engine))


# Open connection with XNAT server
xnat = session.connect_server('xnat',True)
if not xnat :
    if args.verbose:
        print("Error: Could not connect to XNAT")

    sys.exit(1)

#
# Get subject and project IDs
#
try:
    subject_project_list = list(xnat.search( 'xnat:subjectData', ['xnat:subjectData/SUBJECT_LABEL', 'xnat:subjectData/SUBJECT_ID','xnat:subjectData/PROJECT'] ).where( [ ('xnat:subjectData/SUBJECT_LABEL','LIKE', '%')] ).items())
except:
    sys.exit( "ERROR: retrieving subject list from XNAT failed." )

subject_project_dict = dict()
subject_label_to_sid_dict = dict()
for ( subject_label, subject_id, projects ) in subject_project_list:
    subject_project_dict[subject_label] = ( subject_id, projects )
    subject_label_to_sid_dict[subject_label] = subject_id

# Function to get a subject's next visit - this is so we can exclude MRI collected after the next visit date, but still within N days
def get_subject_next_visit_date( subject, after_visit_date ):
    subject_visit_dates = visit_log_redcap.xs( subject, level=0 )['visit_date'].dropna()
    subject_visit_dates = subject_visit_dates[ subject_visit_dates.index.map( lambda key: key != 'recovery_baseline_arm_2' ) ] # Exclude "Recovery" baseline from list - this will usually be the MR day of a normal visit
    later_visits_this_subject = sorted( [ date for date in subject_visit_dates.tolist() if date > after_visit_date ] )
    if len( later_visits_this_subject ) > 0:
        return later_visits_this_subject[0]
    else:
        return None

#
# Main program loop
#
# NCANDA SPICIFIC 
baseline_events = ['baseline_visit_arm_1','baseline_visit_arm_4']
subject_fields = ['study_id', 'dob',  'exclude', 'enroll_exception',
                  'siblings_enrolled', 'siblings_id1', 'hispanic', 'race',
                  'race_other_code']
subject_data = redcap_project.export_records(fields=subject_fields,
                                             events=baseline_events,
                                             event_name='unique',
                                             format='df')
subject_data = pandas.concat([subject_data.xs(event, level=1) for event in baseline_events])
subject_data['siblings_id1'] = subject_data['siblings_id1'].map( lambda x: subject_label_to_sid_dict[x] if x in list(subject_label_to_sid_dict.keys()) else '' )

visit_log_fields = ['study_id', 'redcap_data_access_group', 'visit_date',
                    'mri_qa_completed', 'mri_t1_age', 'mri_dti_age',
                    'mri_rsfmri_age','mri_scanner', 'visit_ignore']
visit_log_redcap = redcap_project.export_records(fields=visit_log_fields,
                                                 event_name='unique',
                                                 export_data_access_groups=True,
                                                 format='df')

if args.site:
    sites = args.site.lower().split( ',' )
    visit_log_redcap = visit_log_redcap[ visit_log_redcap['redcap_data_access_group'].map( lambda dag: dag in sites ) ]

# Filter out all excluded subjects
if args.exclude:
    visit_log_redcap = visit_log_redcap[ visit_log_redcap.index.map( lambda key: False if subject_data['exclude'][key[0]] != 1 else True ) ]
    visit_log_redcap = visit_log_redcap[~visit_log_redcap.visit_date.isnull()]
else:
    visit_log_redcap = visit_log_redcap[ visit_log_redcap.index.map( lambda key: False if subject_data['exclude'][key[0]] == 1 else True ) ]

# Limit to selected events
if args.events:
    events = args.events.lower().split( ',' )
    visit_log_redcap = visit_log_redcap[ visit_log_redcap.index.map( lambda key: key[1] in events ) ]

# Filter out events not yet supported by the pipeline exporter
visit_log_redcap = visit_log_redcap[ visit_log_redcap.index.map( lambda key: key[1] in list(red2cas.get_event_dictionary().keys()) ) ]

forms_by_event_dict = dict()
for event in redcap_project.events:
    event_id = event['unique_event_name']
    forms_by_event_dict[event_id] = set( form_event_mapping[form_event_mapping['unique_event_name'] == event_id ][form_key].tolist() )

# Limit to selected export files
if args.export:
    select_exports = args.export.lower().split( ',' )
else:
    select_exports = None

if args.subject:
    visit_log_redcap = visit_log_redcap.loc[[args.subject]]

if args.verbose:
    print("Exporting %d REDCap records." % len( visit_log_redcap ))

# Iterate over all remaining rows
for [key,row] in visit_log_redcap.iterrows():
    if key[0] not in list(subject_label_to_sid_dict.keys()):
        if args.verbose:
            # there is no xnat id over entire study for this subject , thus no subhect id to write to casesdir, thus ignore  
            print("Missing XNAT ID for subject",key[0])
        continue
    # only do sessions that are not ignored
    if row['visit_ignore___yes'] :
        continue

    subject_xnat_id = subject_label_to_sid_dict[key[0]]
    visit_date = str(row['visit_date'])
    if visit_date == 'nan':
        if args.verbose:
            print("Missing '%s' visit date for subject %s" % ( key[1], key[0] ))
    else:
            this_subject_data = subject_data.ix[key[0]]
            subject_dob_str = str( this_subject_data['dob'] )
            if not re.match( '[0-9]{4}-[0-9]{2}-[0-9]{2}', subject_dob_str ):
                error = "Missing or invalid birthdate '%s' for subject %s" % ( subject_dob_str, key[0] )
                slog.info(str(key[0]), error)
            else:
                visit_age = old_div(red2cas.days_between_dates( subject_dob_str, visit_date ), 365.242)

                # If exclude flag is set, this will override the excludes value and export excluded subjects
                if args.exclude:
                    excludes = 0.0
                else:
                    excludes = 1

                # Check if pipeline directory given and export imaging series there
                if (this_subject_data['exclude'] != excludes):
                    (arm_code,visit_code,subject_datadir_rel) = (None, None, None)
                    try:
                        (arm_code,visit_code,subject_datadir_rel) = red2cas.translate_subject_and_event( subject_xnat_id, key[1] )
                    except: 
                        slog.info("export_measures-" + key[0], "ERROR: Event " + key[1] + " is not supported yet.",
                                      info = "Add event to ncanda_operations/sibis-sys-config.yml")
                        continue

                    if arm_code:
                        subject_datadir = os.path.join(args.pipelinedir,
                                                       subject_datadir_rel)

                        # map the redcap subject key to readable vars
                        redcap_subject, redcap_event = key
                        site = redcap_subject[0]

                        # Handle mapping demographic info for subjects that
                        # changed site
                        if redcap_subject in iter(export_measures_map.keys()):
                            # Only set for visits in the past
                            visit_case_id_map = export_measures_map.get(redcap_subject)
                            
                            case_id_map = visit_case_id_map.get('default')
                            subject_code = case_id_map.get('subject')
                                
                            if visit_code in iter(visit_case_id_map.keys()):
                                case_id_map = visit_case_id_map.get(visit_code)
                            
                            site = case_id_map.get('site')
                            
                            # Make sure results goto the correct directory
                            subject_datadir = subject_datadir.replace(
                                subject_xnat_id, subject_code)
                            subject_xnat_id = subject_code

                        uploads += 1

                        exceeds_criteria_subject = exceeds_criteria_baseline.get(subject_xnat_id)
                        if exceeds_criteria_subject == None:
                             exceeds_criteria_subject_value=-1                             
                        else :
                             exceeds_criteria_subject_value=exceeds_criteria_subject
            
                        # Export measures from RECap into the pipeline.
                        red2cas.export_subject_all_forms(redcap_project,
                                          site,
                                          redcap_subject,
                                          redcap_event,
                                          this_subject_data,
                                          visit_age,
                                          row,
                                          arm_code,
                                          visit_code,
                                          subject_xnat_id,
                                          subject_datadir,
                                          forms_by_event_dict[key[1]],
                                          exceeds_criteria_subject_value,
                                          select_exports=select_exports,
                                          verbose=args.verbose)

                        # Write report of forms locked for this subject, arm,
                        # visit
                        if args.locked_form_report and arm_code == 'standard':
                            # Link directory names with names in REDCap mysql
                            if visit_code == 'baseline' :
                                visit = "Baseline visit"
                            else :
                                visit = visit_code.split('_',1)[1] + " visit"

                            # Get a dataframe of the locked forms
                            arm = "{0} Protocol".format(arm_code.capitalize())

                            locked_forms = red_lock.report_locked_forms(key[0], subject_xnat_id, forms, 'ncanda_subject_visit_log', arm, visit)
                            filename = os.path.join(os.path.abspath(subject_datadir), 'measures', 'locked_forms.csv')
                            sutils.safe_dataframe_to_csv(locked_forms, filename, verbose=args.verbose)

slog.takeTimer1("script_time","{'records': " + str(len(visit_log_redcap)) + ", 'uploads': " +  str(uploads) + "}")
