#!/usr/bin/env python

##
##  See COPYING file distributed along with the ncanda-data-integration package
##  for the copyright and license terms
##

import os
import re
import sys
import hashlib
import requests
import argparse

import sibispy
from sibispy import sibislogger as slog
import pandas
import redcap

# Setup command line parser
parser = argparse.ArgumentParser(description="Update completion status of forms that contain more than one instrument",
                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)
parser.add_argument("-v", "--verbose", help="Verbose operation", action="store_true")
parser.add_argument("--forms", help="Select specific forms to update. Separate multiple forms with commas.", action="store", default=None )
parser.add_argument("-a", "--update-all", help="Update all summary records, regardless of current completion status (otherwise, only 'Complete' forms will be skipped)", action="store_true")
parser.add_argument("-n", "--no-upload", help="Do not upload any scores to REDCap server; instead write to CSV file with given path.", action="store")
parser.add_argument("-p", "--post-to-github", help="Post all issues to GitHub instead of std out.", action="store_true")
parser.add_argument("-t","--time-log-dir",
                    help="If set then time logs are written to that directory (e.g. /fs/ncanda-share/ncanda-data-log/crond)",
                    action="store",
                    default=None)
args = parser.parse_args()

slog.init_log(args.verbose, args.post_to_github,'NCANDA Redcap: Update Form Status (update_bulk_forms)', 'update_bulk_forms', args.time_log_dir)
slog.startTimer1()

session = sibispy.Session()
if not session.configure():
    if args.verbose:
        print "Error: session configure file was not found"

    sys.exit()
#
# Functions 
#


# If connection to redcap server fail, try multiple times
try:
    rc_entry = session.connect_server('data_entry', True)
except Exception, error:
    slog.info(hashlib.sha1('update_bulk_forms').hexdigest()[0:6],
    "ERROR: Could not connect to redcap!",
    script = 'update_bulk_forms',
    msg=str(error))
    sys.exit()

form_event_mapping = rc_entry.export_fem(format='df')

# Compute the bulk "Complete" status of a record based on component status values
def compute_bulk_status( row, field_names, form_complete_field ):
    status = None
    for field in field_names:
        if row[field] < status or not status:
            status = row[field]
    return status

# Process a bulk form with a number of components, each with their own "complete" status
def process_form( form, complete_field_names ):
    # Label of the "Complete" status field for this form
    form_complete_field = '%s_complete' % form

    # Get list of events for which this form exists
    events_this_form = form_event_mapping[ form_event_mapping[ 'form_name' ] == form ]['unique_event_name'].tolist()

    if args.verbose:
        print "Processing events",events_this_form

    # Get fields for applicable events
    try:
        records = rc_entry.export_records( events=events_this_form, fields=[ form_complete_field ] + complete_field_names, event_name='unique', format='df', df_kwargs = { 'index_col': [rc_entry.def_field,'redcap_event_name'], 'dtype' : 'object' } )
    except Exception as e:
        slog.info(
            hashlib.sha1('update_bulk_forms').hexdigest()[0:6],
            "ERROR: Exporting records failed",
            script='update_bulk_forms',
            events=events_this_form,
            fields=[form_complete_field] + complete_field_names,
            index_col = str([rc_entry.def_field, 'redcap_event_name']),
            msg=str(e))
        return

    # Unless we force complete update, drop already-Complete records for speed
    if not args.update_all:
        records = records[ records[form_complete_field].map( str ) != '2' ]

    previous = records[ [form_complete_field] ]
    records[form_complete_field] = records.apply( compute_bulk_status, axis=1, args = (complete_field_names, form_complete_field) ).map( lambda x: str( x ) if not str( x ) == 'nan' else '' )

    # Dump all records where bulk status is unchanged - no need to upload these
    select_records = records[form_complete_field] != previous[form_complete_field]
    records = records[select_records]
    previous = previous[select_records]
    return records[form_complete_field],previous[form_complete_field] 

#
# MAIN  
#

# If list of forms given, only update those
forms_list = rc_entry.forms
records_uploaded = 0

if args.forms:
    forms_list = []
    for form in args.forms.split( ',' ):
        if form in rc_entry.forms:
            forms_list.append( form )
        else:
            print "WARNING: form '%s' does not exist.\n" % form
 
for form in forms_list:
    # Does this form have any "_complete" fields, and if you, which ones?
    complete_field_names = [ field['field_name'] for field in rc_entry.metadata if re.match( '.*_complete$', field['field_name'] ) and (field['form_name'] == form) and (field['field_type'] == 'dropdown') ]

    if len( complete_field_names ) > 0:
        if args.verbose:
            print "Processing bulk form",form

        form_status_out,old_form_status_out = process_form( form, complete_field_names )
        form_status = pandas.DataFrame(form_status_out)

        if args.no_upload:
            form_status.to_csv( args.no_upload )
        else:
            try:
                import_response = rc_entry.import_records( form_status, overwrite='overwrite' )
            except Exception as e:
                # for certain errors find out value 
                remaining_error = [] 
                old_form_status = pandas.DataFrame(old_form_status_out)

                for error in  str(e).split("u'",3)[2].split("\\n"):
                    error_list = error.split('","') 
                    error_list[0] =  error_list[0][1:] 
                    if "This field is located on a form that is locked" in error_list[3] :
                        err_subject_id = error_list[0][:11] 
                        err_event_id = error_list[0][13:-1] 
                        err_field = error_list[1]

                        error_id= err_subject_id + "-" + err_event_id
                        error_index_list = map(lambda (form_subject_id,form_event_id): err_subject_id.strip() == form_subject_id.strip() and err_event_id.strip() == form_event_id.strip(), form_status.index.tolist())
                        new_value = str(form_status[err_field][error_index_list].values) 
                        old_value = str(old_form_status[err_field][error_index_list].values) 

                        slog.info(error_id, "Cannot update '" + err_field + "' field as form is locked",
                                  field = err_field,
                                  value = old_value,
                                  info = "if the current value is unequal to '' and the new value is '' then redcap wont update the form. A possible solution is to select complete for the field.",
                                  new_value = new_value)

                    else : 
                        remaining_error.append(error)

                if remaining_error:
                    log_id = hashlib.sha1(str(e)).hexdigest()[0:6]
                    error_title = 'Exception while importing records into Redcap'
                    slog.info(log_id,
                              error_title,
                              msg=str(remaining_error))
            else:
                if 'count' in import_response.keys():
                    records_uploaded += import_response['count']
                    if args.verbose:
                        print "Uploaded",import_response['count'],"records to REDCap."

slog.takeTimer1("script_time","{'RecordsUploaded': " +  str(records_uploaded) + "}")
