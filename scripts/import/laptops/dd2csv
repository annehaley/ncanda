#!/usr/bin/python

##
##  See COPYING file distributed along with the ncanda-data-integration package
##  for the copyright and license terms
##

# Setup command line parser
import argparse
parser = argparse.ArgumentParser( description="Convert Delayed Discounting results file to CSV" )
parser.add_argument( "-v", "--verbose", help="Verbose operation", action="store_true")
parser.add_argument( "--overwrite", help="Overwrite existing CSV files.", action="store_true")
parser.add_argument( "ddfile", help="Input .txt file with Delayed Discounting results.")
parser.add_argument( "outdir", help="Output directory. All CSV files are created in this directory")
args = parser.parse_args()

# Make a temporary directory
import tempfile
temp_dir_path = tempfile.mkdtemp()

# Read the temporary CSV file
import pandas
dd = pandas.read_csv(args.ddfile, sep='\t', header=None, names=['SubjectID', 'FuturePresent', 'Reward', 'HypReal', 'Exp1', 'Exp2', 'Amount', 'Days', 'DelDisc', 'Version', 'Date'])

# Convert days to integer to avoid comparing floats
dd['Days'] = dd['Days'].map( int )

# Check if this file has the right number of rows.
dd = dd[ dd['FuturePresent'] == 'future' ]
dd = dd[ dd['Reward'] == 'money' ]
dd = dd[ dd['HypReal'] == 'hyp' ]
dd = dd[ dd['Exp1'] == 'gain' ]

# Anything still left? If not, this file has nothing for us.
import sys
if len( dd ) == 0:
    sys.exit( 'WARNING: no suitable data in file %s' % args.ddfile )

# Make sure all rows have the same "Amount", and it's either 100 or 1000
amount = dd['Amount'][0]
if not amount in [100,1000]:
    sys.exit( 'WARNING: amount %f is neither 100 nor 1000 in %s' % (amount,args.ddfile) )
dd = dd[ dd['Amount'] == amount ]

# Now drop the columns we know we don't want anymore
dd = dd.drop(['FuturePresent', 'Reward', 'HypReal', 'Exp1', 'Exp2'], axis=1)

# Make proper subject ID
entered_id = dd['SubjectID'][0].upper()

# First, see if prefix is valid N-CANDA ID
import re
match_id = re.search('^\s*([A-F]-[0-9]{5}-[MFT]-[0-9]).*', entered_id)
if match_id:
    subject_id = match_id.group(1)
else:
    # If that didn't work, truncate off "-1000" or "-100" suffix
    match_id = re.search('^\s*(.*)-1000?$', entered_id)
    if match_id:
        subject_id = match_id.group(1)
    else:
        # Still no luck, just use whatever the RAs entered
        subject_id = entered_id

# Bring "Date" into proper format
match_date = re.search('^([0-9]*)/([0-9]*)/(20[0-9]{2})$', dd['Date'][0])
if match_date:
    date = '%s-%02d-%02d' % (match_date.group(3), int(match_date.group(1)), int(match_date.group(2)))
else:
    sys.exit('ERROR: %s\nCannot extract date from "%s"' % ( args.ddfile, dd['Date'][0] ) )

# Create unique record ID
record_id = '%s-%s' % (subject_id, date)

# Create output table
prefix = 'dd%s' %  amount
data = {'record_id': record_id,
        'visit_information_complete' : 1,
        ('delayed_discounting_%s_complete' % amount) : 1 }

for ( days, field ) in [ (1, '1d'), (7, '7d'), (30, '1mo'), (182, '6mo') ]:
    selection = dd[ dd['Days'] == days ]
    if len( selection ) > 0:
        data[ '%s_logk_%s' % (prefix,field) ] = selection['DelDisc'].tolist()[0]
    else:
        data[ '%s_logk_%s' % (prefix,field) ] = ''

out_df = pandas.DataFrame(data=data, index=[0])

# Determine directory name - create if it doesn't exist
import os
if not os.path.exists(args.outdir):
    os.makedirs(args.outdir)

# Determine file name, only proceed if file does not exist already
filename = os.path.join(args.outdir, '%s-%s.csv' % (record_id, amount))
if not os.path.exists(filename) or args.overwrite:
    out_df.to_csv(filename, index=False)
    # Print filename so we can get a list of updated files by capturing stdout
    print filename

# Clean up - remove temp directory
import shutil
shutil.rmtree(temp_dir_path)
