#!/usr/bin/env python

##
##  See COPYING file distributed along with the ncanda-data-integration package
##  for the copyright and license terms
##

import re
import sys
import string
import argparse
import hashlib

import pandas as pd

import sibispy
from sibispy import sibislogger as slog

parser = argparse.ArgumentParser(description="Import contents of CSV file into "
                                             "non-longitudinal REDCap project")
parser.add_argument("-v", "--verbose",
                    help="Verbose operation",
                    action="store_true")
parser.add_argument("-f", "--force-update",
                    help="Force updates even when records are already marked "
                         "'Complete'",
                    action="store_true")
parser.add_argument( "--project", help="REDCAP project (import_laptops, import_webcnp, or data_entry)", default="import_laptops" )
parser.add_argument("--data-access-group",
                    help="REDCap project data access group that the imported "
                         "data should be assigned to.",
                    default=None)
parser.add_argument("csvfile",
                    nargs='+',
                    help="Input .csv file.")
parser.add_argument("-p", "--post-to-github", help="Post all issues to GitHub instead of std out.", action="store_true")

parser.add_argument("-t","--time-log-dir",
                    help="If set then time logs are written to that directory",
                    action="store",
                    default=None)

args = parser.parse_args()

slog.init_log(args.verbose, args.post_to_github,'NCANDA Import', 'import-laptops-csv2redcap', args.time_log_dir)
slog.startTimer1()

# Open connection to REDCap server

session = sibispy.Session()
if not session.configure():
    if args.verbose:
        print "Error: session configure file was not found"

    sys.exit()

project = session.connect_server(args.project, True)

if not project:
    if args.verbose:
        print "Error: Could not connect to Redcap"

    sys.exit()

# List of failed files
failed = []


# Process one file.
def process_file(fname):
    # Read input file
    global records
    global uploaded

    data = pd.read_csv(fname, dtype=object)

    # Replace periods in column labels with underscores
    data.rename(columns=lambda s: string.lower(s.replace('.', '_')),
                inplace=True)

    # Bring original "siteid" column back to assign each record to the correct
    # data access group
    if args.data_access_group:
        data['redcap_data_access_group'] = args.data_access_group

    # Get "complete" field of existing records so we can protect "Complete"
    # records from overwriting
    complete_field = None
    for var in data.columns:
        if re.match('.*_completed$', var) and \
                not var == 'visit_information_complete':
            complete_field = var

    # Is there a "complete" field? Then get existing records and ditch all
    # records from new data that are "Complete"
    if complete_field:
        existing_data = project.export_records(fields=[complete_field],
                                               format='df')

    # Make list of dicts for REDCap import
    record_list = []
    for key, row in data.iterrows():
        row['record_id'] = re.sub('(#|&|\+|\')', '?', row['record_id'])
        record_id = row['record_id']
        if complete_field:
            if record_id in existing_data.index.tolist():
                if existing_data[complete_field][record_id] == 2:
                    if args.force_update:
                        print "Forcing update of 'Complete' record", record_id
                    else:
                        continue
        record = dict(row.dropna().apply(lambda s: re.sub('&quot;', '""', s)))
        record_list.append(record)

    # Upload new data to REDCap
    try: 
        import_response = project.import_records(record_list, overwrite='overwrite')

    except Exception as err_msg: 
        slog.info(hashlib.sha1('import-laptops-csv2redcap' + str(err_msg)).hexdigest()[0:6], "Upload error to redcap",
                  error_msg=str(err_msg),
                  record_list =str(record_list), 
                  cmd_args = str(sys.argv),
                  file_name = fname)
        failed.append(fname)
        return 

        
    # If there were any errors, try to print them as well as possible
    if 'error' in import_response.keys():
        error = "Upload error"
        slog.info(hashlib.sha1('import-laptops-csv2redcap {}'.format(import_response['error'])).hexdigest()[0:6], error,
                  error_msg=str(import_response['error']))

    if 'fields' in import_response.keys():
        for field in import_response['fields']:
            print "\t", field

    if 'records' in import_response.keys():
        for record in import_response['records']:
            print "\t", record

    # Finally, print upload status if so desired
    if 'count' in import_response.keys():
        uploaded += import_response['count']
        records += len(data)
        if args.verbose:
            print "Successfully uploaded %d/%d records to REDCap." % \
                  (import_response['count'], len(data))
    else:
        failed.append(fname)

# Process all files from the command line
uploaded = 0 
records = 0
for f in args.csvfile:
    process_file(f)

# Print failures
if len(failed) > 0:
    slog.info(hashlib.sha1('import-laptops-csv2redcap {}'.format(' '.join(failed))).hexdigest()[0:6], "ERROR uploading file(s)", 
              files_not_uploaded = str(failed) )
    sys.exit()

slog.takeTimer1("script_time","{'records': " + str(records) +  ", 'uploads': " +  str(uploaded) + "}")
