#!/usr/bin/env python

##
##  See COPYING file distributed along with the ncanda-data-integration package
##  for the copyright and license terms
##

import os
import re
import stat
import time
import argparse
import subprocess
import datetime
import pyxnat
import sys

import sibispy
from sibispy import sibislogger as slog



session = sibispy.Session()
if not session.configure():
    print "Error: session configure file was not found"

    sys.exit()



parser = argparse.ArgumentParser( description="Find new MR sessions in XNAT, check for missing and duplicate scans, and list all sessions with questionable scans." )
parser.add_argument("-v", "--verbose", action="store_true", default=False, help="Verbose operation.")
parser.add_argument("-m", "--send-mail", action="store_true", default=False, help="Send emails with problem reports to users and site admin.")
parser.add_argument("-e", "--eidlist", default =False, action='store',help="Allows for a subset of scans to be selected for export - write to file with eid in each line")
parser.add_argument( "-a", "--check-all", help="Check all subjects and sessions, regardless of date.", action="store_true")
parser.add_argument( "-W", "--last-week", help="Check all subjects and sessions that were modified within the last week.", action="store_true")
parser.add_argument( "-M", "--last-month", help="Check all subjects and sessions that were modified within the last month (more precisely: the last 31 days).", action="store_true")
parser.add_argument( "--no-update", help="Do not update the persistent data stored on the XNAT server (e.g., last run date, list of flagged sessions).", action="store_true")
parser.add_argument("--zip-root", default=session.config.get('zip-root'), help="Root directory to create ZIP archives with T1w and T2w DICOM files for clinical reading.")
parser.add_argument("--zip-none", action="store_true", default=False, help="Do not create any ZIP archives (T1w and T2w DICOM files for clinical reading).")
parser.add_argument("--zip-all", action="store_true", default=False, help="Create ZIP archives (T1w and T2w DICOM files for clinical reading) for all sessions, regardless of whether or not they have been processed before.")
parser.add_argument("-p", "--post-to-github", help="Post all issues to GitHub instead of std out.", action="store_true")
parser.add_argument("-t","--time-log-dir",
                    help="If set then time logs are written to that directory (e.g. /fs/ncanda-share/ncanda-data-log/crond)",
                    action="store",
                    default=None)
args = parser.parse_args()

# Setup logging
slog.init_log(args.verbose, args.post_to_github,'NCANDA XNAT: Check Object Names Message', 'check_object_names', args.time_log_dir)
slog.startTimer1()

# Get one or more custom variables from XML representation of experiment
def get_custom_variables( experiment, field_names, default_value=None ):
    xml = experiment.get()
    values = []
    for field_name in field_names:
        field_regex = '.*<xnat:field name="%s">(.*?)</xnat:field>' % field_name.lower()
        match = re.match( field_regex, xml, flags=re.DOTALL )
        if match:
            values.append( re.sub( '\s*<!--.*?-->\s*', '', match.group( 1 ), flags=re.DOTALL ) )
        else:
            values.append( default_value )
    return values

#
# Export T1w and T2w DICOM files to ZIP archive
#
def export_t1t2_to_zip( experiment, experiment_label ):
    # Get list of all scans in the session
    scan_dirs = []
    for scan in experiment.scans().get():
        scan_type = experiment.scan( scan ).attrs.get( 'type' )
        if ('t1spgr' in scan_type) or ('mprage' in scan_type) or ('t2fse' in scan_type):
            match = re.match('.*(/fs/storage/XNAT/.*)scan_.*_catalog.xml.*', experiment.scan(scan).get(), re.DOTALL)
            if match:
                # Replace the path stored in XNAT with the NFS mount path.
                xnat_path = match.group(1).replace('storage/XNAT',
                                                   'ncanda-xnat')
                scan_dirs.append(xnat_path)

    if len( scan_dirs ) > 0:
        if args.verbose:
            print "INFO: exporting T1w and T2w DICOM files for",experiment,"/",experiment_label

        # Remove common prefix to make archive more flat
        if len( scan_dirs ) > 1:
            basedir = os.path.commonprefix( scan_dirs )
            scan_dirs_rel = [ re.sub( basedir, '', sdir ) for sdir in scan_dirs ]
        else:
            basedir = re.sub( 'SCANS/.*', 'SCANS/', scan_dirs[0] )
            scan_dirs_rel = [ re.sub( '.*/SCANS/', '', scan_dirs[0] ) ]

        # Get today's date for naming
        date_today = time.strftime( '%Y-%m-%d', time.localtime() )

        # Check if output directory is already there
        outdir = os.path.join( args.zip_root, date_today )
        if not os.path.exists( outdir ):
            os.makedirs( outdir )
            os.chmod( outdir, stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO )

        # Create ZIP file
        zipfile = os.path.join( outdir, experiment_label+'.zip' )
        zip_command = 'cd %s; /usr/bin/zip -rqu %s %s' % (basedir, zipfile, ' '.join(scan_dirs_rel))
        try:
            subprocess.check_call( zip_command, shell=True )
        except:
            error = 'ERROR: unable to create ZIP file from these directories'
            slog.info(zipfile, error,
                         scan_dirs = ' '.join( scan_dirs ))
            print zip_command
            try:
                os.remove(zipfile)
            except:
                pass

        if os.path.exists( zipfile ):
            os.chmod( zipfile, stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO )
            if args.verbose:
                print "Successfully created T1/T2 DICOM archive",zipfile
            try:
                experiment.attrs.set( 'xnat:mrSessionData/fields/field[name=datetodvd]/field', date_today )
            except:
                error = "ERROR: failed to set DateToDVD field on experiment - removing archive file"
                slog.info(experiment_label,error,
                              zipfile = zipfile)
                os.remove( zipfile )

    return len( scan_dirs ) > 0

# RegExp pattern for subject IDs
subject_id_pattern = '^[A-FX]-[0-9]{5}-[MFPT]-[0-9]$'

# RegExp pattern for experiment labels
experiment_label_pattern = '^[A-FX]-[0-9]{5}-[MFPT]-[0-9]-20[0-9]{2}[01][0-9][0-3][0-9](-[0-9]){0,1}$'

#
# Check an experiment (MR session)
#
def validate_experiment( ifc, project, sid, slabel, eid, elabel, edate, einsert ):
    if args.verbose:
        print "INFO: checking experiment %s (%s)" % (elabel,eid)

    global email

    check_again = []

    # in date, ditch the hyphens, which aren't supposed to be in the session label
    edate_short = re.sub( '-', '', edate )

    # Check for correct label, but only if subject ID isn't wrong
    if re.match( subject_id_pattern, slabel ):
        correct_label = '%s-%s' % ( slabel, edate_short )
        if re.match( '^%s(-[0-9]){0,1}' % correct_label, elabel ):
            if not 'P' in slabel:
                experiment = ifc.select.project( project ).subject( sid ).experiment( eid )
                edvddate = get_custom_variables( experiment, [ 'DateToDVD' ] )[0]
                if args.zip_all or (edvddate == None) or not re.match( '^2[0,1][0-9]{2}-[0-1][0-9]-[0-3][0-9]$', edvddate ):
                    if not args.zip_none:
                        # Export T1/T2 DICOM files; returns "True" if any exist
                        if export_t1t2_to_zip( experiment, elabel ):
                            # so check again until DatetoDVD is filled in with a date 
                            # not sure this is the best logic
                            check_again.append( eid )
                    else:
                        check_again.append( eid )
        else:
            check_again.append( eid )
            if args.send_mail:
                experiment_uri = 'https://ncanda.sri.com/xnat/app/action/DisplayItemAction/search_element/xnat:mrSessionData/search_field/xnat:mrSessionData.ID/search_value/%s/popup/false' % eid
                email.add_user_message( einsert, 'Session "%s" (<a href="%s">%s</a>) is not named correctly (should be: "%s")' % (elabel, experiment_uri, eid, correct_label) )
            else:
                print 'Session "%s" (%s) is not named correctly (should be: "%s")' % (elabel, eid, correct_label)
    else:
        # If subject ID was incorrect, match Session Name against pattern instead of (unknown) correct label
        if not re.match( experiment_label_pattern, elabel ):
            check_again.append( eid )
            if args.send_mail:
                experiment_uri = 'https://ncanda.sri.com/xnat/app/action/DisplayItemAction/search_element/xnat:mrSessionData/search_field/xnat:mrSessionData.ID/search_value/%s/popup/false' % eid
                email.add_user_message( einsert, 'Session "%s" (<a href="%s">%s</a>) does not conform with naming convention (fix subject ID first)' % (elabel, experiment_uri, eid) )
            else:
                print 'Session "%s" (%s) does not conform to naming convention' % (elabel, eid)

    return check_again

#
# Check a subject ID, then check each experiment
#
def validate_subject( ifc, sid, slabel, sinsert ):
    if args.verbose:
        print "INFO: checking subject %s (%s)" % ( slabel, sid )

    global email

    check_again = []

    # Check subject label
    if not re.match( subject_id_pattern, slabel ):
        check_again.append( sid )
        if args.send_mail:
            subject_uri = 'https://ncanda.sri.com/xnat/app/action/DisplayItemAction/search_element/xnat:subjectData/search_field/xnat:subjectData.ID/search_value/%s' % sid
            email.add_user_message( sinsert, 'Subject name "%s" (<a href="%s">%s</a>) does not conform with ID convention' % (slabel, subject_uri, sid) )
        else:
            print 'Subject name "%s" (%s) does not conform to ID convention' % (slabel, sid)

    return check_again

#
# Check each subject in the project
#
experiment_list = None
subject_list = None

def validate_new_and_outstanding( ifc, project, objects_to_check, date_last_checked ):
    # Get all subjects and sessions from XNAT - this speeds things up a lot
    subject_list = ifc.select( 'xnat:subjectData', ['xnat:subjectData/SUBJECT_ID','xnat:subjectData/SUBJECT_LABEL','xnat:subjectData/INSERT_USER','xnat:subjectData/INSERT_DATE'] ).where( [ ('xnat:subjectData/PROJECT','LIKE', '%'+project+'%') ] )
    experiment_list = ifc.select( 'xnat:mrSessionData', ['xnat:mrSessionData/SESSION_ID','xnat:mrSessionData/LABEL','xnat:mrSessionData/SUBJECT_ID','xnat:mrSessionData/DATE','xnat:mrSessionData/INSERT_USER','xnat:mrSessionData/LAST_MODIFIED'] ).where( [ ('xnat:mrSessionData/PROJECT','LIKE', '%'+project+'%') ] )

    check_again = []
    if len( subject_list ) > 0:
        subject_lookup = dict()
        # First, check each subject
        for (sid,slabel,sinsert,sdate) in subject_list.items():
            subject_lookup[sid] = slabel
            if (sid in objects_to_check) or (sdate > date_last_checked):
                check_again += validate_subject( ifc, sid, slabel, sinsert )

                if len( [ eid for ( eid,elabel,esid,edate,einsert,emodified ) in experiment_list.items() if sid == esid ] ) == 0:
                    check_again.append( sid )
                    if args.send_mail:
                        subject_uri = 'https://ncanda.sri.com/xnat/app/action/DisplayItemAction/search_element/xnat:subjectData/search_field/xnat:subjectData.ID/search_value/%s/project/%s' % (sid,project)
                        email.add_user_message( sinsert, 'Subject "%s" (<a href="%s">%s</a>) does not have any MR sessions. Consider deleting it.' % (slabel, subject_uri, sid) )
                    else:
                        print 'Subject name "%s" (%s) does not have any MR sessions' % (slabel, sid)

        # Second check each experiment
        if len(experiment_list) > 0:
            for eid, elabel, sid, edate, einsert, emodified in experiment_list.items():
                if (eid in objects_to_check) or (emodified > date_last_checked):
                    if sid in subject_lookup.keys():
                        check_again += validate_experiment(ifc, project, sid, subject_lookup[sid], eid, elabel, edate, einsert)
                    else:
                        error = 'ERROR: cannot determine (unique) label'
                        slog.info(eid, error,
                                      subject=sid,
                                      project=project,
                                      date=edate)

    return check_again


# Create interface using stored configuration
ifc = session.connect_server('xnat', True)
ifc._memtimeout = 0

# Set up email object to contact users and admin
from xnat_email import XnatEmail
email = XnatEmail( ifc )

# Experiments to check from last run - these should be the ones we flagged last time and stored on the server for reconsideration
objects_to_check = []

# Date format for XNAT dates and current date and time
xnat_date_format = '%Y-%m-%d %H:%M:%S'
now_str = time.strftime( xnat_date_format )

# Date (and time) when we last checked things
date_last_checked = time.localtime(0)

config_uri = '/data/config/pyxnat/check_object_names'
if not args.check_all:
    try:
        # Retrieve script config from XNAT server
        content = ifc._get_json( '%s' % config_uri )

        # Extract date this script was last run
        creation_date = content[0]['create_date']
        date_last_checked = time.strptime( creation_date[0:19], xnat_date_format )
        if args.verbose:
            print 'Script was last run %s' % creation_date

        if args.eidlist:
            with open(args.eidlist,'r') as f:
                eidlist = f.read().split()
            objects_to_check = eidlist
        else :
            # Get list of previously flagged experiments that need to be checked again
            # Remove new line at the last element as otherwise dropped from list 
            objects_to_check_list =  content[0]['contents'][0:-1]
            # Only check if not NONE
            if objects_to_check_list != "NONE": 
                objects_to_check = set( objects_to_check_list.split( ',' ) )

        if args.verbose:
            print 'Re-checking %d previously flagged objects' % len( objects_to_check )

    except:
        # If we cannot get last script run date from server, leave at epoch (Jan 1, 1970)
        if args.verbose:
            print 'Unable to retrieve date of last script run and list of flagged projects from server.'

        ifc = session.connect_server('xnat', True)
        ifc._memtimeout = 0

# If "last week" option is used, override last checked date
if args.last_week:
    date_last_checked = (datetime.datetime.now() - datetime.timedelta(7)).timetuple()

# If "last month" option is used, override last checked date
if args.last_month:
    date_last_checked = (datetime.datetime.now() - datetime.timedelta(31)).timetuple()

# For comparison - convert time of last check to string in XNAT date format
str_date_last_checked = time.strftime( xnat_date_format, date_last_checked )

# Get a list of all MR imaging sessions
project_ids = ifc.select.projects().get()
check_again = []
for pid in project_ids:
    check_again += validate_new_and_outstanding( ifc, pid, objects_to_check, str_date_last_checked )

if args.send_mail:
    email.send_all()

# Finally, update config stored on the server to have current date/time as the time that this script was last run
if not args.no_update:
    if args.verbose:
        print "Flagging %d objects for re-inspection during next script run" % len( check_again )

    if len( check_again ) > 0:
        check_again_str = ','.join( set( check_again ) )
    else :
        check_again_str = 'NONE'

    content = ifc._exec( uri='%s?inbody=true' % config_uri, method='PUT', body=check_again_str, headers={'content-type':'text/plain'} )

slog.takeTimer1("script_time","{'TotalSubjects': " + str(len(subject_list)) + ", 'TotalExperiments': " +  str(len(experiment_list)) + "}")