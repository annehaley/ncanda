#!/usr/bin/env python

##
##  See COPYING file distributed along with the ncanda-data-integration package
##  for the copyright and license terms
##

from __future__ import print_function
import re
import sys
import json
import time
import argparse

import fmri_qa_functions as qa
import t1_qa_functions as t1qa
import sibispy
import hashlib 
from sibispy import sibislogger as slog

# Define command line options for this script
formatter = argparse.RawDescriptionHelpFormatter
default = 'default: %(default)s'
parser = argparse.ArgumentParser(prog="phantom_qa",
                                 description=__doc__,
                                 formatter_class=formatter)
parser.add_argument("-v", "--verbose", action="store_true", dest="verbose", default=False, help="Verbose operation.")
parser.add_argument("-f", "--force-updates", action="store_true", dest="force_updates", default=False, help="Force updates of QA analyses for all phantom scan experiments.")
parser.add_argument("-a", "--check-all", action="store_true", dest="check_all", default=False, help="Check all phantom sessions, regardless of date.")
parser.add_argument("--exclude-adni", action="store_true", dest="exclude_adni", default=False, help="Exclude all (structural) ADNI phantom scans.")
parser.add_argument("--exclude-fbirn", action="store_true", dest="exclude_fbirn", default=False, help="Exclude all (functional) fBIRN phantom scans.")
parser.add_argument("--subj-label", action="store", dest="subj_label", default=None, help="Limit processing by subject_label, e.g., C-70019-F-2-20160513")
parser.add_argument("-p", "--post-to-github", help="Post all issues to GitHub instead of std out.", action="store_true")
parser.add_argument("-t","--time-log-dir",
                    help="If set then time logs are written to that directory",
                    action="store",
                    default=None)

args = parser.parse_args()

slog.init_log(args.verbose, args.post_to_github, 'NCANDA XNAT', 'phantom_qa',
              args.time_log_dir)
slog.startTimer1()

counter_records = 0
counter_uploads = 0

# Create interface using stored configuration
session = sibispy.Session()
if not session.configure():
    if args.verbose:
        print("Error: session configure file was not found")

    sys.exit()

# Create interface using stored configuration
interface = session.connect_server('xnat', True)
if not interface:
    if args.verbose:
        print("Error: Could not connect to XNAT")

    sys.exit()
interface._memtimeout = 0

# Date format for XNAT dates
xnat_date_format = '%Y-%m-%d %H:%M:%S'
now_str = time.strftime( xnat_date_format )

# Date (and time) when we last checked things
date_last_checked = time.localtime(0)
config_uri = '/data/config/pyxnat/fmri_qa_phantom'
try:
    # Retrieve script config from XNAT server
    content = interface._exec( config_uri, format='json' )
    # Extract date this script was last run
    creation_date = json.loads( content )['ResultSet']['Result'][0]['create_date']
    date_last_checked = time.strptime( creation_date[0:19], xnat_date_format )
    if args.verbose:
        print('Script was last run %s' % creation_date)
except:
    # If we cannot get last script run date from server, leave at epoch (Jan 1, 1970)
    if args.verbose:
        print('Unable to retrieve date of last script run from server.')

# For comparison - convert time of last check to string in XNAT date format
str_date_last_checked = time.strftime( xnat_date_format, date_last_checked )


def process_fbirn(phantom_subjects_IDs,xnat_dir):
    global counter_records, counter_uploads
    for [phantom, project, label] in phantom_subject_IDs:
        counter_records += 1
        # For each phantom subject (one per project), get the IDs and last_modified dates of all its imaging sessions
        phantom_sessions = interface.search('xnat:mrSessionData',
                                            ['xnat:mrSessionData/SESSION_ID', 'xnat:mrSessionData/LABEL',
                                             'xnat:mrSessionData/LAST_MODIFIED']) \
            .where([('xnat:mrSessionData/LABEL', '=', label)]).items()
        # Iterate over all imaging sessions
        for [session, label, last_modified] in phantom_sessions:
            counter_uploads += 1
            if (last_modified > str_date_last_checked) or args.force_updates \
                    or args.check_all or args.subj_label:
                if args.verbose:
                    print('Running fBIRN phantom QA for session {0} in project {1}'.format(session, project))
                qa.process_phantom_session(interface, project, phantom, session,
                                           label, xnat_dir,force_updates=args.force_updates)

def process_adni(phantom_subjects_IDs,xnat_dir):
    global counter_records, counter_uploads
    for [phantom, project, label] in phantom_subject_IDs:
        counter_records += 1
        # For each phantom subject (one per project), get the IDs and last_modified dates of all its imaging sessions
        phantom_sessions = interface.search('xnat:mrSessionData',
                                            ['xnat:mrSessionData/SESSION_ID', 'xnat:mrSessionData/LABEL',
                                             'xnat:mrSessionData/LAST_MODIFIED']) \
            .where([('xnat:mrSessionData/LABEL', '=', label)]).items()
        # Iterate over all imaging sessions
        for [session, label, last_modified] in phantom_sessions:
            counter_uploads += 1
            if (last_modified > str_date_last_checked) or args.force_updates \
                    or args.check_all or args.subj_label:
                if args.verbose:
                    print('Running ADNI phantom QA for session {0} in project {1}'.format(session, project))
                t1qa.process_phantom_session(interface, project, phantom, session, label, xnat_dir,
                                             force_updates=options.force_updates)


if args.subj_label:
    # Adjust the constraints for one subject id
    constraints = [('xnat:mrSessionData/LABEL', '=', args.subj_label)]
    # Search XNAT database for all Subjects that have the fBIRN with constraints from parameter
    phantom_subject_IDs = interface.search('xnat:mrSessionData',
                                           ['xnat:mrSessionData/SUBJECT_ID', 'xnat:mrSessionData/PROJECT',
                                           'xnat:mrSessionData/LABEL']) \
                                           .where(constraints).items()
    for subject_id, project, label in phantom_subject_IDs:
        if re.match('^[A-Z]-00000-P-0', label):
            process_fbirn(phantom_subject_IDs,session.get_xnat_dir())
        elif re.match('^[A-Z]-99999-P-9',label):
            process_adni(phantom_subject_IDs,session.get_xnat_dir())
        else:
            print("subject_label did not match re for phantom label '^[A-Z]-00000-P-0' or '^[A-Z]-99999-P-9'")
            sys.exit(1)


if args.exclude_adni:
    # General constraints to get all fBIRN phantoms
    constraints = [('xnat:mrSessionData/LABEL', 'LIKE','%-00000-P-0-%')]
    # Search XNAT database for all Subjects that have the fBIRN with constraints from parameter
    phantom_subject_IDs = interface.search('xnat:mrSessionData',
                                           ['xnat:mrSessionData/SUBJECT_ID', 'xnat:mrSessionData/PROJECT',
                                            'xnat:mrSessionData/LABEL']) \
                                           .where(constraints).items()
    process_fbirn(phantom_subject_IDs,session.get_xnat_dir())

if args.exclude_fbirn:
    # General constraints to get all adni phantoms
    constraints = [('xnat:mrSessionData/LABEL', 'LIKE', '%-99999-P-9-%')]
    # Search XNAT database for all Subjects that have the fBIRN with constraints from parameter
    phantom_subject_IDs = interface.search('xnat:mrSessionData',
                                           ['xnat:mrSessionData/SUBJECT_ID', 'xnat:subjectData/PROJECT',
                                            'xnat:mrSessionData/LABEL']) \
                                           .where(constraints).items()
    process_adni(phantom_subject_IDs,session.get_xnat_dir())

# Finally, update config stored on the server to have current date/time as the time that this script was last run
# (but don't update config if we excluded either ADNI of fBIRN phantom scans this time around)
if not args.exclude_fbirn and not args.exclude_adni:
    try : 
        content = interface._exec( uri=config_uri, query={'inbody':'true'}, method='PUT', body=now_str, headers={'content-type':'text/plain'} )
    except Exception as err_msg: 
        slog.info(hashlib.sha1(str(err_msg)).hexdigest()[0:6],'ERROR: Could not write to xnat',
                  err_msg = str(err_msg))
        sys.exit(1) 


slog.takeTimer1("script_time","{'records': " + str(counter_records) + ",'uploads': " + str(counter_uploads) + "}")
