#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Get a table of processing status for all LimeSurvey files that fit criteria.

Note that while the criteria allow for glob-like use, it's Python glob, not
bash glob - so asterisk works as expected, but options in curly brackets do
not!

Sample uses:

- Retrieve all raw *and* processed 2018 files for all subjects that begin with
  E-00207:

    ./find_limesurvey_status all --subject='E-00207-*' --date="2018*"

- Retrieve only processed youthreport1 files for subjects beginning with
  A-00002:

    ./find_limesurvey_status proc --subject='A-00002-*' --form-name='youthreport1'

- Get all raw files collected between April 10 and April 19, 2018:

    ./find_limesurvey_status.py raw --date="2018041?"

Room for improvement:

- Use *only* correct matching IDs and dates extracted from files
- Correctly identify lssaga_youth vs. _parent
- Fuzzy-match IDs
- Use a sliding time window
- Fail gracefully when something cannot be retrieved and/or found
"""
from glob import glob
import pandas as pd
import os
import sys
import fire
from functools import wraps
import sibispy
from limesurvey_utils import (limesurvey_number_to_name,
                              limesurvey_name_to_number,
                              limesurvey_name_glob_to_names,
                              limesurvey_name_glob_to_numbers,
                              get_within_file_info,
                              get_import_url,
                              get_completion_status_in_redcap,
                              get_completion_status_for_pipe)
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
# warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)


def find_processed_limesurvey_forms(subject='*', form_name='*', date='*',
                                    path='/fs/storage/laptops/imported'):
    """
    Given glob information, get a DataFrame of matching processed LS files
    """
    date = str(date)
    if len(date) == 8 and "-" not in date:
        date = "%s-%s-%s" % (date[0:4], date[4:6], date[6:8])
    glob_pattern = "%s/*/limesurvey/%s/%s-%s.csv" % (
        path, form_name, subject, date
    )
    matched_files = glob(glob_pattern)
    files = pd.DataFrame({'proc_path': matched_files,
                          'proc_site': [f.split('/')[-4]
                                        for f in matched_files],
                          'proc_form': [f.split('/')[-2]
                                        for f in matched_files],
                          'proc_name': [os.path.basename(f)
                                        for f in matched_files]})
    if files.empty:
        return files
    files[['import_id', 'proc_subj', 'proc_date']] = (files['proc_name']
                                                      .str.extract(
        r'(([A-Z]-\d{5}-[MFTX]-\d)-(\d{4}-\d{2}-\d{2}))'
    ))
    files['proc_date'] = files['proc_date'].str.replace('-', '')
    return (files
            .sort_values(['proc_date'])
            .pipe(get_import_url)
            .pipe(get_completion_status_for_pipe, import_api))


def find_raw_limesurvey_uploads(subject='*', form_number='*', date='*',
                                path='/fs/storage/laptops/ncanda'):
    """
    Given glob information, get a DataFrame of matching raw LS files
    """
    if date != '*':
        # Should probably try to parse it?
        # assert len(date) == 8
        pass
    # If date contains dashes, that's no bueno for raw files -> remove
    date = date.replace('-', '')

    glob_pattern = "%s/*/%s[-_]%s/survey_%s*.csv" % (
        path, subject, date, form_number
    )
    matched_files = glob(glob_pattern)
    files = pd.DataFrame({'raw_path': matched_files,
                          'raw_name': [os.path.basename(f)
                                       for f in matched_files]})
    if files.empty:
        return files
    files['svn_origin'] = files['raw_path'].str.split('/').str.get(-3)
    files['raw_site'] = files['svn_origin'].str.extract('([a-z]+)')
    files[['raw_ls_number', 'raw_subj', 'raw_date']] = (files['raw_name']
                                                        .str.extract(
        r'survey_(\d{5,6})_subjid_([A-Z]-\d{5}-[MFTX]-\d)[_-](\d{8})'
    ))
    nonnull_ls_number = files['raw_ls_number'].notnull()
    files.loc[nonnull_ls_number,
              'raw_form'] = (files.loc[nonnull_ls_number, 'raw_ls_number']
                             .apply(limesurvey_number_to_name, short=True,
                                    raise_error=False))
    # 4. Within-file ID (main)
    # 5. Within-file ID (others)
    # 6. Within-file date (main)
    # 7. Within-file date (others)
    # return files.raw_path.apply(get_within_file_info, is_lssaga=True)
    return files.sort_values(['raw_date'])


def find_raw2processed_status(subject='*',
                              form_number=None,
                              form_name=None,
                              date='*',
                              raw_path='/fs/storage/laptops/ncanda',
                              processed_path='/fs/storage/laptops/imported',
                              droptests=True,
                              trim=True,
                              # FIXME: The following options should either be
                              # documented or removed (or, better still,
                              # extracted to a different function that inherits
                              # from this one)
                              showunmatched=False,
                              orphaned=False,
                              unharvested=False,):
    # First, need to convert the two ways of getting form type to be compatible
    if not form_number and not form_name:
        form_numbers = ['*']
        form_names = ['*']
    elif form_number:  # FIXME: Assuming exact number, which might be incorrect
        form_numbers = [form_number]
        form_names = [limesurvey_number_to_name(form_number, short=True)]
    elif form_name:
        form_numbers = limesurvey_name_glob_to_numbers(form_name)
        form_names = limesurvey_name_glob_to_names(form_name)

    raw_dfs = [find_raw_limesurvey_uploads(subject, number, date, raw_path)
               for number in form_numbers]
    proc_dfs = [find_processed_limesurvey_forms(subject, name, date,
                                                processed_path)
                for name in form_names]

    raw_df = pd.concat(raw_dfs, axis=0)
    proc_df = pd.concat(proc_dfs, axis=0)

    # FIXME: With more introspection, we'll want to be merging on different IDs
    if raw_df.empty and proc_df.empty:
        return pd.DataFrame()
    elif raw_df.empty:
        # df_all = proc_df
        return proc_df
    elif proc_df.empty:
        # df_all = raw_df
        return raw_df
    else:
        df_all = (pd.merge(raw_df, proc_df,
                           how='outer',
                           left_on=['raw_subj', 'raw_date', 'raw_form'],
                           right_on=['proc_subj', 'proc_date', 'proc_form']))

    df_all['subj'] = df_all.apply(
        lambda x: x.raw_subj if not pd.isnull(x.raw_subj) else x.proc_subj,
        axis=1)
    df_all['date'] = df_all.apply(
        lambda x: x.raw_date if not pd.isnull(x.raw_subj) else x.proc_date,
        axis=1)
    df_all['form'] = df_all.apply(
        lambda x: x.raw_form if not pd.isnull(x.raw_subj) else x.proc_form,
        axis=1)
    df_all = df_all.dropna(subset=['subj'])
    if droptests:
        df_all = df_all.loc[~df_all['subj'].str.contains('[TX]')]
    df_all = (df_all
              .drop(axis=1,
                    labels=['raw_subj', 'proc_subj',
                            'raw_date', 'proc_date',
                            'raw_form', 'proc_form', ])
              .set_index(['subj', 'date', 'form'])
              .sort_index())

    # If only interested in problem entries
    unharvested_idx = df_all['url'].isnull()
    noparent_idx = df_all['raw_path'].isnull()

    if showunmatched or (orphaned and unharvested):
        df_all = df_all.loc[unharvested_idx | noparent_idx]
    elif orphaned:
        df_all = df_all.loc[noparent_idx]
    elif unharvested:
        df_all = df_all.loc[unharvested_idx]

    if trim:
        wanted_cols = ['raw_path', 'proc_path', 'status', 'url']
        # TODO: Check if available
        return df_all[wanted_cols]
    else:
        return df_all


if __name__ == "__main__":
    # Set up sibispy
    session = sibispy.Session()
    OFFLINE = True
    import_api = None
    if session.configure():
        OFFLINE = False
        import_api = session.connect_server('import_laptops')
    # Set display properties
    # *_path often exceeds max_colwidth -> remove that limitation
    pd.set_option('display.max_colwidth', -1)
    pd.set_option('display.max_rows', None)

    # Modify the functions for proper str output
    def __str_decorator(fn):
        """
        Strip objects returned to Python Fire to __str__.

        (Otherwise, Fire would show object content + docstring + properties.)
        """
        @wraps(fn)  # to preserve fn.__name__ - inessential otherwise
        def stringiated_fn(*args, **kwargs):
            """
            Any fn, just with __str__ called to its output
            """
            output = fn(*args, **kwargs)
            if type(output) == pd.DataFrame and output.empty:
                # Don't print anything for an empty DataFrame
                return None
            else:
                return output.__str__
        return stringiated_fn

    # Modify the functions for CSV output
    def __csv_decorator(fn):
        """
        Apply .to_csv to object returned by function
        """
        @wraps(fn)  # to preserve fn.__name__ - inessential otherwise
        def csvfied_fn(*args, **kwargs):
            """
            Any fn, just with .to_csv() called to its output
            """
            return fn(*args, **kwargs).to_csv(sys.stdout)
        return csvfied_fn

    fns = [find_raw_limesurvey_uploads,
           find_processed_limesurvey_forms,
           find_raw2processed_status, ]
    fns_str = {fn.__name__: __str_decorator(fn) for fn in fns}
    fns_csv = {fn.__name__: __csv_decorator(fn) for fn in fns}

    # Register the modified functions
    fire.Fire({
        'all': fns_str['find_raw2processed_status'],
        'all_csv': fns_csv['find_raw2processed_status'],
        'all_df': find_raw2processed_status,
        'raw': fns_str['find_raw_limesurvey_uploads'],
        'raw_csv': fns_csv['find_raw_limesurvey_uploads'],
        'raw_df': find_raw_limesurvey_uploads,
        'proc': fns_str['find_processed_limesurvey_forms'],
        'proc_csv': fns_csv['find_processed_limesurvey_forms'],
        'proc_df': find_processed_limesurvey_forms,
    })
